# -*- coding: utf-8 -*-
from .deps import *

class PetSearchAnalyzer:
    def __init__(self, file_path, file_type, results_dir):
        self.file_type = file_type
        self.file_path = file_path
        self.results_dir = results_dir  # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.stats_results = {}
        print(f"üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞: {os.path.basename(file_path)}")
        
        self.df = self.load_proper_csv(file_path)
        
        if not self.df.empty:
            self.preprocess_data()
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
    
    def load_proper_csv(self, file_path):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç CSV —Ñ–∞–π–ª —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –ø–∞—Ä—Å–∏–Ω–≥–æ–º –∫–∞–≤—ã—á–µ–∫, –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É"""
        try:
            encodings = ['utf-8', 'cp1251', 'latin1']
            
            for encoding in encodings:
                try:
                    with open(file_path, 'r', encoding=encoding) as f:
                        reader = csv.reader(f)
                        rows = list(reader)
                    
                    if rows:
                        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π {encoding}")
                        break
                except UnicodeDecodeError:
                    continue
            else:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª —Å –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∞–º–∏")
                return pd.DataFrame()
            
            if len(rows) > 1:
                data_rows = rows[1:]
                print(f"üìä –°—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö: {len(data_rows)}")
            else:
                print("‚ùå –í —Ñ–∞–π–ª–µ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∫—Ä–æ–º–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞")
                return pd.DataFrame()
            
            column_names = [
                'url', 'id', '—Ç–∏–ø_–æ–±—ä—è–≤–ª–µ–Ω–∏—è', '—Ä–µ–≥–∏–æ–Ω', '—Å—Ç–∞—Ç—É—Å', '—Ç–∏–ø_–∂–∏–≤–æ—Ç–Ω–æ–≥–æ', 
                '–æ–∫—Ä–∞—Å', '–ø–æ—Ä–æ–¥–∞', '–º–µ—Å—Ç–æ_—Å–æ–±—ã—Ç–∏—è', '–¥–∞—Ç–∞_–ø—É–±–ª–∏–∫–∞—Ü–∏–∏', '–ø–æ–ª', 
                '–≤–æ–∑—Ä–∞—Å—Ç', '–æ–ø–∏—Å–∞–Ω–∏–µ', '–¥–ª–∏–Ω–∞_–æ–ø–∏—Å–∞–Ω–∏—è', '–Ω–∞–ª–∏—á–∏–µ_–æ–ø–∏—Å–∞–Ω–∏—è', 
                '–µ—Å—Ç—å_—Ñ–æ—Ç–æ', '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ñ–æ—Ç–æ', '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤', 
                '–¥–∞—Ç–∞_—Å–æ–±—ã—Ç–∏—è', '–µ—Å—Ç—å_–∫–æ–Ω—Ç–∞–∫—Ç—ã'
            ]
            
            df = pd.DataFrame(data_rows, columns=column_names[:len(data_rows[0])])
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫ —Å {len(df.columns)} –∫–æ–ª–æ–Ω–∫–∞–º–∏")
            
            return df
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {e}")
            return pd.DataFrame()
        
    def preprocess_data(self):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        print("üîß –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        
        df = self.df.copy()
        
        # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ—Ç –ª–∏—à–Ω–∏—Ö –∫–∞–≤—ã—á–µ–∫ –∏ –ø—Ä–æ–±–µ–ª–æ–≤
        for col in df.columns:
            df[col] = df[col].astype(str).str.strip().str.strip('"').str.strip("'")
        
        # –ü—Ä–∏–≤–æ–¥–∏–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        text_columns = ['—Ç–∏–ø_–æ–±—ä—è–≤–ª–µ–Ω–∏—è', '—Ä–µ–≥–∏–æ–Ω', '—Å—Ç–∞—Ç—É—Å', '—Ç–∏–ø_–∂–∏–≤–æ—Ç–Ω–æ–≥–æ', 
                       '–ø–æ–ª', '–æ–∫—Ä–∞—Å', '–ø–æ—Ä–æ–¥–∞', '–º–µ—Å—Ç–æ_—Å–æ–±—ã—Ç–∏—è']
        
        for col in text_columns:
            if col in df.columns:
                df[col] = df[col].str.lower()
        
        # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é is_success
        if '—Å—Ç–∞—Ç—É—Å' in df.columns:
            if self.file_type == 'lost':
                df['is_success'] = df['—Å—Ç–∞—Ç—É—Å'].str.contains('–Ω–∞–π–¥–µ–Ω', na=False)
            else:
                df['is_success'] = df['—Å—Ç–∞—Ç—É—Å'].str.contains('—Ö–æ–∑—è–∏–Ω –Ω–∞–π–¥–µ–Ω', na=False)
            
            df['is_success'] = df['is_success'].astype(int)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∏–Ω–∞—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        binary_mapping = {'true': 1, 'false': 0, '–¥–∞': 1, '–Ω–µ—Ç': 0, '1': 1, '0': 0}
        binary_columns = ['–Ω–∞–ª–∏—á–∏–µ_–æ–ø–∏—Å–∞–Ω–∏—è', '–µ—Å—Ç—å_—Ñ–æ—Ç–æ', '–µ—Å—Ç—å_–∫–æ–Ω—Ç–∞–∫—Ç—ã']
        
        for col in binary_columns:
            if col in df.columns:
                df[col] = df[col].str.lower().map(binary_mapping).fillna(0).astype(int)
        
        # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö
        numeric_columns = ['–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ñ–æ—Ç–æ', '–¥–ª–∏–Ω–∞_–æ–ø–∏—Å–∞–Ω–∏—è', '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤']
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        
        self.df_processed = df
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(df)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
        print(f"‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤: {df['is_success'].sum()} ({df['is_success'].mean()*100:.1f}%)")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.stats_results['base_success_rate'] = df['is_success'].mean()
        self.stats_results['total_ads'] = len(df)
        self.stats_results['successful_ads'] = df['is_success'].sum()
    
    def plot_success_by_animal_type(self):
        """–ì—Ä–∞—Ñ–∏–∫ 3 –∏ 7: –î–æ–ª—è —É—Å–ø–µ—Ö–∞ –ø–æ —Ç–∏–ø–∞–º –∂–∏–≤–æ—Ç–Ω—ã—Ö"""
        if '—Ç–∏–ø_–∂–∏–≤–æ—Ç–Ω–æ–≥–æ' not in self.df_processed.columns:
            return
        
        df = self.df_processed
        animal_success = df.groupby('—Ç–∏–ø_–∂–∏–≤–æ—Ç–Ω–æ–≥–æ')['is_success'].agg(['count', 'mean']).round(3)
        animal_success = animal_success[animal_success['count'] >= 3]
        animal_success = animal_success.sort_values('mean', ascending=False)
        
        fig, ax = plt.subplots(figsize=(10, 7))
        
        bars = ax.bar(animal_success.index, animal_success['mean'] * 100, 
                      color='lightgreen', alpha=0.7)
        
        title = f'–î–æ–ª—è —É—Å–ø–µ—Ö–∞ "–ø–æ—Ç–µ—Ä—è–Ω" –ø–æ —Ç–∏–ø–∞–º –∂–∏–≤–æ—Ç–Ω—ã—Ö' if self.file_type == 'lost' else f'–î–æ–ª—è —É—Å–ø–µ—Ö–∞ "–Ω–∞–π–¥–µ–Ω" –ø–æ —Ç–∏–ø–∞–º –∂–∏–≤–æ—Ç–Ω—ã—Ö'
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞
        max_value = max(animal_success['mean'] * 100)
        title_y = 1.05 if max_value > 70 else 1.02
        ax.set_title(title, fontsize=14, fontweight='bold', y=title_y)
        
        ax.set_ylabel('–î–æ–ª—è —É—Å–ø–µ—Ö–∞, %', fontsize=12)
        ax.set_xlabel('–¢–∏–ø –∂–∏–≤–æ—Ç–Ω–æ–≥–æ', fontsize=12)
        plt.xticks(rotation=45, ha='right')
        ax.grid(axis='y', alpha=0.3)
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Ä—Ö–Ω–∏–π –ª–∏–º–∏—Ç –æ—Å–∏ Y —á—Ç–æ–±—ã –±—ã–ª–æ –º–µ—Å—Ç–æ –¥–ª—è —Ç–µ–∫—Å—Ç–∞
        ax.set_ylim(0, max(animal_success['mean'] * 100) * 1.15)
        
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 1,
                    f'{height:.1f}%', ha='center', va='bottom', fontweight='bold',
                    fontsize=9)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.9)
        
        filename = f"3.1.3 –î–æ–ª—è —É—Å–ø–µ—à–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤ –ø–æ —Ç–∏–ø—É –∂–∏–≤–æ—Ç–Ω–æ–≥–æ –¥–ª—è '{self.file_type}'.png"
        # –ò–ó–ú–ï–ù–ò–¢–¨ –ø—É—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        plt.savefig(os.path.join(self.results_dir, filename), dpi=300, bbox_inches='tight')
        plt.close()
        
        return animal_success
    
    
    def calculate_animal_statistics(self):
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–∏–ø–∞–º –∂–∏–≤–æ—Ç–Ω—ã—Ö"""
        if '—Ç–∏–ø_–∂–∏–≤–æ—Ç–Ω–æ–≥–æ' not in self.df_processed.columns:
            return
        
        df = self.df_processed
        animal_stats = df.groupby('—Ç–∏–ø_–∂–∏–≤–æ—Ç–Ω–æ–≥–æ').agg({
            'is_success': ['count', 'sum', 'mean']
        }).round(4)
        animal_stats.columns = ['count', 'success_count', 'success_rate']
        
        self.stats_results['animal_success_rates'] = animal_stats['success_rate'].to_dict()
        
        return animal_stats
    
    def calculate_photo_statistics(self):
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ñ–æ—Ç–æ"""
        photo_stats = {}
        
        if '–µ—Å—Ç—å_—Ñ–æ—Ç–æ' in self.df_processed.columns:
            photo_presence = self.df_processed.groupby('–µ—Å—Ç—å_—Ñ–æ—Ç–æ')['is_success'].mean()
            photo_stats['has_photo_impact'] = {
                0: float(photo_presence.get(0, 0)),
                1: float(photo_presence.get(1, 0))
            }
        
        if '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ñ–æ—Ç–æ' in self.df_processed.columns:
            df = self.df_processed.copy()
            df['—Ñ–æ—Ç–æ_–≥—Ä—É–ø–ø–∞'] = pd.cut(df['–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ñ–æ—Ç–æ'], 
                                      bins=[-1, 0, 1, 2, 3, 5, 100],
                                      labels=['0', '1', '2', '3', '4-5', '6+'])
            
            photo_count_stats = df.groupby('—Ñ–æ—Ç–æ_–≥—Ä—É–ø–ø–∞')['is_success'].mean()
            photo_stats['photo_count_impact'] = photo_count_stats.to_dict()
        
        self.stats_results['photo_statistics'] = photo_stats
        return photo_stats
    
    def calculate_description_statistics(self):
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é"""
        desc_stats = {}
        
        if '–Ω–∞–ª–∏—á–∏–µ_–æ–ø–∏—Å–∞–Ω–∏—è' in self.df_processed.columns:
            desc_presence = self.df_processed.groupby('–Ω–∞–ª–∏—á–∏–µ_–æ–ø–∏—Å–∞–Ω–∏—è')['is_success'].mean()
            desc_stats['has_description_impact'] = {
                0: float(desc_presence.get(0, 0)),
                1: float(desc_presence.get(1, 0))
            }
        
        if '–¥–ª–∏–Ω–∞_–æ–ø–∏—Å–∞–Ω–∏—è' in self.df_processed.columns:
            df = self.df_processed.copy()
            df['–æ–ø–∏—Å–∞–Ω–∏–µ_–≥—Ä—É–ø–ø–∞'] = pd.cut(df['–¥–ª–∏–Ω–∞_–æ–ø–∏—Å–∞–Ω–∏—è'], 
                                          bins=[-1, 0, 10, 20, 30, 50, 100, 1000],
                                          labels=['0', '1-10', '11-20', '21-30', '31-50', '51-100', '100+'])
            
            desc_length_stats = df.groupby('–æ–ø–∏—Å–∞–Ω–∏–µ_–≥—Ä—É–ø–ø–∞')['is_success'].mean()
            desc_stats['description_length_impact'] = desc_length_stats.to_dict()
        
        self.stats_results['description_statistics'] = desc_stats
        return desc_stats
    
    def calculate_contacts_statistics(self):
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–æ–Ω—Ç–∞–∫—Ç–∞–º"""
        if '–µ—Å—Ç—å_–∫–æ–Ω—Ç–∞–∫—Ç—ã' not in self.df_processed.columns:
            return
        
        contacts_stats = self.df_processed.groupby('–µ—Å—Ç—å_–∫–æ–Ω—Ç–∞–∫—Ç—ã')['is_success'].mean()
        self.stats_results['contacts_impact'] = {
            0: float(contacts_stats.get(0, 0)),
            1: float(contacts_stats.get(1, 0))
        }
        
        return contacts_stats
    
    def save_statistics(self, output_dir=None):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ —Ñ–∞–π–ª—ã"""
        if output_dir is None:
            # –ò–°–ü–û–õ–¨–ó–û–í–ê–¢–¨ –ø–∞–ø–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            output_dir = os.path.join(self.results_dir, '3.1 Stats for 3.2 Prediction')
        
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        filename = f"pet911_{self.file_type}_statistics.json"
        filepath = os.path.join(output_dir, filename)
        
        def convert_to_serializable(obj):
            if isinstance(obj, (np.integer, np.floating)):
                return float(obj)
            elif isinstance(obj, dict):
                return {k: convert_to_serializable(v) for k, v in obj.items()}
            elif isinstance(obj, (list, tuple)):
                return [convert_to_serializable(x) for x in obj]
            else:
                return obj
        
        serializable_stats = convert_to_serializable(self.stats_results)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(serializable_stats, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {filepath}")
        
        self.save_detailed_stats_csv(output_dir)
        
        return filepath
    
    def save_detailed_stats_csv(self, output_dir):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ CSV"""
        filename = f"pet911_{self.file_type}_detailed_stats.csv"
        filepath = os.path.join(output_dir, filename)
        
        detailed_data = []
        
        detailed_data.append({
            'category': 'base',
            'factor': 'base_success_rate',
            'value': self.stats_results['base_success_rate'],
            'description': '–ë–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏'
        })
        
        if 'animal_success_rates' in self.stats_results:
            for animal, rate in self.stats_results['animal_success_rates'].items():
                detailed_data.append({
                    'category': 'animal_type',
                    'factor': animal,
                    'value': rate,
                    'description': f'–£—Å–ø–µ—à–Ω–æ—Å—Ç—å –¥–ª—è {animal}'
                })
        
        if 'photo_statistics' in self.stats_results:
            photo_stats = self.stats_results['photo_statistics']
            if 'has_photo_impact' in photo_stats:
                detailed_data.append({
                    'category': 'photo',
                    'factor': 'no_photo',
                    'value': photo_stats['has_photo_impact'].get(0, 0),
                    'description': '–£—Å–ø–µ—à–Ω–æ—Å—Ç—å –±–µ–∑ —Ñ–æ—Ç–æ'
                })
                detailed_data.append({
                    'category': 'photo', 
                    'factor': 'with_photo',
                    'value': photo_stats['has_photo_impact'].get(1, 0),
                    'description': '–£—Å–ø–µ—à–Ω–æ—Å—Ç—å —Å —Ñ–æ—Ç–æ'
                })
        
        df_detailed = pd.DataFrame(detailed_data)
        df_detailed.to_csv(filepath, index=False, encoding='utf-8')
        print(f"üìä –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {filepath}")

    def comprehensive_analysis(self):
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤"""
        print(f"\n{'='*60}")
        print(f"üöÄ –ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó - {self.file_type.upper()}")
        print(f"{'='*60}")
        
        total_ads = len(self.df_processed)
        success_ads = self.df_processed['is_success'].sum()
        success_rate = self.df_processed['is_success'].mean() * 100
        
        print(f"üìà –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   –í—Å–µ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {total_ads}")
        print(f"   –£—Å–ø–µ—à–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤: {success_ads}")
        print(f"   –£—Ä–æ–≤–µ–Ω—å —É—Å–ø–µ—Ö–∞: {success_rate:.1f}%")
        
        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤
        print(f"\nüìä –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤...")
        
        # –ì—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Ç–∏–ø–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        self.plot_success_by_animal_type()

        
        # –†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        print(f"\nüìä –†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è...")
        self.calculate_animal_statistics()
        self.calculate_photo_statistics()
        self.calculate_description_statistics()
        self.calculate_contacts_statistics()
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        saved_file = self.save_statistics()
        
        print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –ø—Ä–æ–≥–Ω–æ–∑–Ω–æ–π –º–æ–¥–µ–ª–∏")
        
        return self.stats_results

def plot_comparison_charts(lost_analyzer, found_analyzer):
    """–ì—Ä–∞—Ñ–∏–∫–∏ 1 –∏ 2: –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è –æ–±–æ–∏—Ö —Ñ–∞–π–ª–æ–≤"""
    
    fig = plt.figure(figsize=(12, 5))
    
    # –ì—Ä–∞—Ñ–∏–∫ 1: –î–∏–∞–≥—Ä–∞–º–º–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
    plt.subplot(1, 2, 1)
    types = ['–ü–æ—Ç–µ—Ä—è–Ω', '–ù–∞–π–¥–µ–Ω']
    counts = [len(lost_analyzer.df_processed), len(found_analyzer.df_processed)]
    colors = ['lightblue', 'lightcoral']
    
    plt.pie(counts, labels=types, autopct='%1.1f%%', colors=colors)
    plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –æ–±—ä—è–≤–ª–µ–Ω–∏–π', fontsize=14, fontweight='bold', y=1.05)
    
    # –ì—Ä–∞—Ñ–∏–∫ 2: –î–æ–ª—è —É—Å–ø–µ—Ö–∞ –ø–æ —Ç–∏–ø–∞–º –æ–±—ä—è–≤–ª–µ–Ω–∏–π
    plt.subplot(1, 2, 2)
    lost_success = lost_analyzer.df_processed['is_success'].mean() * 100
    found_success = found_analyzer.df_processed['is_success'].mean() * 100
    
    bars = plt.bar(['–ü–æ—Ç–µ—Ä—è–Ω', '–ù–∞–π–¥–µ–Ω'], [lost_success, found_success], 
                  color=['lightblue', 'lightcoral'])
    plt.title('–î–æ–ª—è —É—Å–ø–µ—Ö–∞ –ø–æ —Ç–∏–ø–∞–º –æ–±—ä—è–≤–ª–µ–Ω–∏–π', fontsize=14, fontweight='bold', y=1.05)
    plt.ylabel('–î–æ–ª—è —É—Å–ø–µ—Ö–∞, %', fontsize=12)
    
    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Ä—Ö–Ω–∏–π –ª–∏–º–∏—Ç –æ—Å–∏ Y
    max_value = max(lost_success, found_success)
    plt.ylim(0, max_value * 1.15)
    
    for bar in bars:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height + 1,
                f'{height:.1f}%', ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    plt.subplots_adjust(top=0.85)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–º–µ—Å—Ç–æ –ø–æ–∫–∞–∑–∞ - –ò–ó–ú–ï–ù–ò–¢–¨ –ø—É—Ç—å
    results_dir = lost_analyzer.results_dir  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞–ø–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    plt.savefig(os.path.join(results_dir, "3.1.1.+3.1.2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏ —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞ –ø–æ —Ç–∏–ø–∞–º –æ–±—ä—è–≤–ª–µ–Ω–∏–π.png"), 
                dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"\nüìä –°–í–û–î–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"   –ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ –∂–∏–≤–æ—Ç–Ω—ã–µ: {lost_success:.1f}% —É—Å–ø–µ—Ö–∞")
    print(f"   –ù–∞–π–¥–µ–Ω–Ω—ã–µ –∂–∏–≤–æ—Ç–Ω—ã–µ: {found_success:.1f}% —É—Å–ø–µ—Ö–∞")

def step_3_1():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã –∞–Ω–∞–ª–∏–∑–∞"""

    warnings.filterwarnings('ignore')

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
    plt.style.use('default')
    sns.set_palette("husl")

    print("üéØ –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–• PET911 - –°–û–•–†–ê–ù–ï–ù–ò–ï –°–¢–ê–¢–ò–°–¢–ò–ö–ò")
    print("=" * 60)
    
    # –°–û–ó–î–ê–ï–ú –ü–ê–ü–ö–£ –î–õ–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
    results_dir = "results/–†–µ–∑—É–ª—å—Ç–∞—Ç—ã 3 –≥–ª–∞–≤—ã –∞–Ω–∞–ª–∏–∑–∞"
    os.makedirs(results_dir, exist_ok=True)
    print(f"üìÅ –°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {results_dir}")
    
    # –§–∞–π–ª—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    lost_file = 'data/Dataset_final_Pet911_lost.csv'
    found_file = 'data/dataset_final_Pet911_found.csv'
    
    all_statistics = {}
    analyzers = {}
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã—Ö –∂–∏–≤–æ—Ç–Ω—ã—Ö
    if os.path.exists(lost_file):
        print(f"\n{'üîç'*20} –ê–ù–ê–õ–ò–ó –ü–û–¢–ï–†–Ø–ù–ù–´–• –ñ–ò–í–û–¢–ù–´–• {'üîç'*20}")
        # –ü–ï–†–ï–î–ê–ï–ú –ü–ê–ü–ö–£ –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –í –ö–û–ù–°–¢–†–£–ö–¢–û–†
        lost_analyzer = PetSearchAnalyzer(lost_file, 'lost', results_dir)
        if not lost_analyzer.df.empty:
            stats_lost = lost_analyzer.comprehensive_analysis()
            all_statistics['lost'] = stats_lost
            analyzers['lost'] = lost_analyzer
    else:
        print(f"‚ùå –§–∞–π–ª {lost_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    # –ê–Ω–∞–ª–∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∂–∏–≤–æ—Ç–Ω—ã—Ö
    if os.path.exists(found_file):
        print(f"\n{'üîç'*20} –ê–ù–ê–õ–ò–ó –ù–ê–ô–î–ï–ù–ù–´–• –ñ–ò–í–û–¢–ù–´–• {'üîç'*20}")
        # –ü–ï–†–ï–î–ê–ï–ú –ü–ê–ü–ö–£ –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –í –ö–û–ù–°–¢–†–£–ö–¢–û–†
        found_analyzer = PetSearchAnalyzer(found_file, 'found', results_dir)
        if not found_analyzer.df.empty:
            stats_found = found_analyzer.comprehensive_analysis()
            all_statistics['found'] = stats_found
            analyzers['found'] = found_analyzer
    else:
        print(f"‚ùå –§–∞–π–ª {found_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    # –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏
    if 'lost' in analyzers and 'found' in analyzers:
        print(f"\n{'üìä'*20} –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–´–ï –ì–†–ê–§–ò–ö–ò {'üìä'*20}")
        plot_comparison_charts(analyzers['lost'], analyzers['found'])
    
    print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ '{results_dir}/'")
    print("üí° –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º—É –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è!")

