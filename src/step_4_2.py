from .deps import *



def create_directories():
    """
    –°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
    """
    base_dir = "results/–†–µ–∑—É–ª—å—Ç–∞—Ç—ã 4 –≥–ª–∞–≤—ã –∞–Ω–∞–ª–∏–∑–∞"
    clustering_dir = os.path.join(base_dir, "4.2. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
    os.makedirs(base_dir, exist_ok=True)
    os.makedirs(clustering_dir, exist_ok=True)
    
    
    return base_dir, clustering_dir

def load_and_prepare_data(lost_file, found_file):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –¥–≤—É—Ö —Ñ–∞–π–ª–æ–≤ –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏—Ö.
    """
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df_lost = pd.read_csv(lost_file)
    df_found = pd.read_csv(found_file)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∫—É —Ç–∏–ø–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
    df_lost['–æ–±—ä—è–≤–ª–µ–Ω–∏–µ_—Ç–∏–ø'] = 'lost'
    df_found['–æ–±—ä—è–≤–ª–µ–Ω–∏–µ_—Ç–∏–ø'] = 'found'
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã
    df_combined = pd.concat([df_lost, df_found], ignore_index=True)
    
    # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é is_success
    success_conditions = (
        (df_combined['—Å—Ç–∞—Ç—É—Å'] == '–ø–∏—Ç–æ–º–µ—Ü –Ω–∞–π–¥–µ–Ω') | 
        (df_combined['—Å—Ç–∞—Ç—É—Å'] == '—Ö–æ–∑—è–∏–Ω –Ω–∞–π–¥–µ–Ω')
    )
    df_combined['is_success'] = success_conditions
    
    print(f"–í—Å–µ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {len(df_combined)}")
    print(f"–£—Å–ø–µ—à–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤: {df_combined['is_success'].sum()}")
    
    return df_combined

def create_clustering_features(df):
    """
    –°–æ–∑–¥–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –∑–∞—è–≤–æ–∫.
    """
    print("\n–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏...")
    
    # 1. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ (–ø—Ä—è–º–æ–π –ø—Ä–∏–∑–Ω–∞–∫)
    df['–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ñ–æ—Ç–æ_–Ω–æ—Ä–º'] = df['–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ñ–æ—Ç–æ'].fillna(0)
    
    # 2. –î–ª–∏–Ω–∞ –æ–ø–∏—Å–∞–Ω–∏—è (–ø—Ä—è–º–æ–π –ø—Ä–∏–∑–Ω–∞–∫)
    df['–¥–ª–∏–Ω–∞_–æ–ø–∏—Å–∞–Ω–∏—è_–Ω–æ—Ä–º'] = df['–î–ª–∏–Ω–∞_–æ–ø–∏—Å–∞–Ω–∏—è_–≤_—Å–ª–æ–≤–∞—Ö'].fillna(0)
    
    # 3. –ü–æ–ª–Ω–æ—Ç–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è (–≤—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–ª–µ–π)
    key_columns = ['—Ç–∏–ø_–∂–∏–≤–æ—Ç–Ω–æ–≥–æ', '–ø–æ—Ä–æ–¥–∞', '–ø–æ–ª', '–≤–æ–∑—Ä–∞—Å—Ç', '–æ–∫—Ä–∞—Å', '–º–µ—Å—Ç–æ —Å–æ–±—ã—Ç–∏—è']
    
    def calculate_completeness(row):
        filled = 0
        total = len(key_columns)
        
        for col in key_columns:
            if (col in row and 
                pd.notna(row[col]) and 
                str(row[col]).strip() not in ['', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ', 'Unknown']):
                filled += 1
        
        return filled / total if total > 0 else 0
    
    df['–ø–æ–ª–Ω–æ—Ç–∞_–∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è'] = df.apply(calculate_completeness, axis=1)
    
    # 4. –°–∫–æ—Ä–æ—Å—Ç—å –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (—Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É –¥–∞—Ç–æ–π —Å–æ–±—ã—Ç–∏—è –∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏)
    def parse_date(date_str):
        """–ü–∞—Ä—Å–∏—Ç –¥–∞—Ç—É –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞ '–≤—Å, 12.10.2025'"""
        try:
            if pd.isna(date_str):
                return None
            # –£–±–∏—Ä–∞–µ–º –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏ –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
            date_part = str(date_str).split(',')[-1].strip()
            return datetime.strptime(date_part, '%d.%m.%Y')
        except:
            return None
    
    # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—ã
    df['–¥–∞—Ç–∞_–ø—É–±–ª–∏–∫–∞—Ü–∏–∏_–ø–∞—Ä—Å'] = df['–¥–∞—Ç–∞_–ø—É–±–ª–∏–∫–∞—Ü–∏–∏'].apply(parse_date)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–æ–ª–±–µ—Ü —Å –¥–∞—Ç–æ–π —Å–æ–±—ã—Ç–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
    def get_event_date(row):
        if row['–æ–±—ä—è–≤–ª–µ–Ω–∏–µ_—Ç–∏–ø'] == 'lost':
            return parse_date(row['–¥–∞—Ç–∞ –ø—Ä–æ–ø–∞–∂–∏'])
        else:
            return parse_date(row['–¥–∞—Ç–∞ –Ω–∞—Ö–æ–¥–∫–∏'])
    
    df['–¥–∞—Ç–∞_—Å–æ–±—ã—Ç–∏—è_–ø–∞—Ä—Å'] = df.apply(get_event_date, axis=1)
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–Ω–∏—Ü—É –≤ –¥–Ω—è—Ö
    def calculate_time_diff(row):
        if pd.isna(row['–¥–∞—Ç–∞_–ø—É–±–ª–∏–∫–∞—Ü–∏–∏_–ø–∞—Ä—Å']) or pd.isna(row['–¥–∞—Ç–∞_—Å–æ–±—ã—Ç–∏—è_–ø–∞—Ä—Å']):
            return 0
        diff = (row['–¥–∞—Ç–∞_–ø—É–±–ª–∏–∫–∞—Ü–∏–∏_–ø–∞—Ä—Å'] - row['–¥–∞—Ç–∞_—Å–æ–±—ã—Ç–∏—è_–ø–∞—Ä—Å']).days
        return max(0, diff)  # –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–µ –∏–º–µ—é—Ç —Å–º—ã—Å–ª–∞
    
    df['—Å–∫–æ—Ä–æ—Å—Ç—å_–ø—É–±–ª–∏–∫–∞—Ü–∏–∏_–¥–Ω–∏'] = df.apply(calculate_time_diff, axis=1)
    
    # 5. –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –æ–±—Å—É–∂–¥–µ–Ω–∏—è
    df['–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å_–æ–±—Å—É–∂–¥–µ–Ω–∏—è'] = df['–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤'].fillna(0)
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
    clustering_features = df[[
        '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ñ–æ—Ç–æ_–Ω–æ—Ä–º', '–¥–ª–∏–Ω–∞_–æ–ø–∏—Å–∞–Ω–∏—è_–Ω–æ—Ä–º', '–ø–æ–ª–Ω–æ—Ç–∞_–∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è',
        '—Å–∫–æ—Ä–æ—Å—Ç—å_–ø—É–±–ª–∏–∫–∞—Ü–∏–∏_–¥–Ω–∏', '–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å_–æ–±—Å—É–∂–¥–µ–Ω–∏—è'
    ]].copy()
    
    # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
    clustering_features = clustering_features.fillna(0)
    
    print("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏:")
    print(clustering_features.describe().round(2))
    
    return clustering_features, df

def find_optimal_clusters(features_scaled, clustering_dir):
    """
    –ù–∞—Ö–æ–¥–∏—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤.
    """
    print("\n–ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤...")
    
    silhouette_scores = []
    wcss = []  # Within-Cluster Sum of Square
    k_range = range(2, 8)
    
    for k in k_range:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        cluster_labels = kmeans.fit_predict(features_scaled)
        
        silhouette_scores.append(silhouette_score(features_scaled, cluster_labels))
        wcss.append(kmeans.inertia_)
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤—ã–±–æ—Ä–∞ k
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # Elbow method
    ax1.plot(k_range, wcss, 'bo-', linewidth=2, markersize=8)
    ax1.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
    ax1.set_ylabel('WCSS (Within-Cluster Sum of Square)')
    ax1.set_title('Elbow Method')
    ax1.grid(True, alpha=0.3)
    
    # Silhouette score
    ax2.plot(k_range, silhouette_scores, 'ro-', linewidth=2, markersize=8)
    ax2.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
    ax2.set_ylabel('Silhouette Score')
    ax2.set_title('Silhouette Analysis')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–ø–∫—É –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
    output_path = os.path.join('results/–†–µ–∑—É–ª—å—Ç–∞—Ç—ã 4 –≥–ª–∞–≤—ã –∞–Ω–∞–ª–∏–∑–∞/4.2.1. –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    # –í—ã–±–∏—Ä–∞–µ–º k=4 —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
    optimal_k = 4
    print(f"–í—ã–±—Ä–∞–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {optimal_k}")
    
    return optimal_k

def perform_clustering(features_scaled, optimal_k):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é K-means.
    """
    print(f"\n–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ —Å {optimal_k} –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏...")
    
    kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
    cluster_labels = kmeans.fit_predict(features_scaled)
    
    silhouette_avg = silhouette_score(features_scaled, cluster_labels)
    print(f"–°—Ä–µ–¥–Ω–∏–π silhouette score: {silhouette_avg:.3f}")
    
    return cluster_labels, kmeans

def visualize_clusters_2d(features_scaled, cluster_labels, feature_names, clustering_dir):
    """
    –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–ª–∞—Å—Ç–µ—Ä—ã –≤ 2D –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ —Å –ø–æ–º–æ—â—å—é PCA.
    """
    print("\n–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –≤ 2D...")
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º PCA –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ 2D
    pca = PCA(n_components=2, random_state=42)
    features_2d = pca.fit_transform(features_scaled)
    
    # –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Å–∏–≤—É—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
    
    # 1. –ë–∞–∑–æ–≤–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
    scatter1 = ax1.scatter(features_2d[:, 0], features_2d[:, 1], 
                          c=cluster_labels, cmap='viridis', alpha=0.7, s=50)
    ax1.set_xlabel('–ì–ª–∞–≤–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 1')
    ax1.set_ylabel('–ì–ª–∞–≤–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 2')
    ax1.set_title('–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (PCA)\n–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –æ–±—ä—è–≤–ª–µ–Ω–∏–π –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è')
    ax1.grid(True, alpha=0.3)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
    explained_var = pca.explained_variance_ratio_
    ax1.text(0.02, 0.98, f'–û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è:\nPC1: {explained_var[0]:.1%}\nPC2: {explained_var[1]:.1%}', 
             transform=ax1.transAxes, verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
    
    # 2. –£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å —Ü–µ–Ω—Ç—Ä–æ–∏–¥–∞–º–∏
    unique_clusters = np.unique(cluster_labels)
    colors = plt.cm.viridis(np.linspace(0, 1, len(unique_clusters)))
    
    for i, cluster_id in enumerate(unique_clusters):
        cluster_points = features_2d[cluster_labels == cluster_id]
        ax2.scatter(cluster_points[:, 0], cluster_points[:, 1], 
                   c=[colors[i]], label=f'–ö–ª–∞—Å—Ç–µ—Ä {cluster_id}', alpha=0.7, s=50)
        
        # –¶–µ–Ω—Ç—Ä–æ–∏–¥ –∫–ª–∞—Å—Ç–µ—Ä–∞
        centroid = cluster_points.mean(axis=0)
        ax2.scatter(centroid[0], centroid[1], marker='*', s=300, 
                   c=[colors[i]], edgecolors='black', linewidth=2)
    
    ax2.set_xlabel('–ì–ª–∞–≤–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 1')
    ax2.set_ylabel('–ì–ª–∞–≤–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 2')
    ax2.set_title('–ö–ª–∞—Å—Ç–µ—Ä—ã —Å —Ü–µ–Ω—Ç—Ä–æ–∏–¥–∞–º–∏')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–ø–∫—É –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
    output_path = os.path.join('results/–†–µ–∑—É–ª—å—Ç–∞—Ç—ã 4 –≥–ª–∞–≤—ã –∞–Ω–∞–ª–∏–∑–∞/4.2.2. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    return features_2d

def create_cluster_profiles(df, cluster_labels, feature_names):
    """
    –°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ—Ñ–∏–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ—Ç –∏—Ö.
    """
    print("\n–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª–µ–π –∫–ª–∞—Å—Ç–µ—Ä–æ–≤...")
    
    # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –≤ –∏—Å—Ö–æ–¥–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º
    df_result = df.copy()
    df_result['cluster'] = cluster_labels
    
    # –ê–Ω–∞–ª–∏–∑ —Å—Ä–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
    cluster_analysis = df_result.groupby('cluster').agg({
        '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ñ–æ—Ç–æ_–Ω–æ—Ä–º': 'mean',
        '–¥–ª–∏–Ω–∞_–æ–ø–∏—Å–∞–Ω–∏—è_–Ω–æ—Ä–º': 'mean',
        '–ø–æ–ª–Ω–æ—Ç–∞_–∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è': 'mean',
        '—Å–∫–æ—Ä–æ—Å—Ç—å_–ø—É–±–ª–∏–∫–∞—Ü–∏–∏_–¥–Ω–∏': 'mean',
        '–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å_–æ–±—Å—É–∂–¥–µ–Ω–∏—è': 'mean',
        'is_success': 'mean',
        'id': 'count'
    }).round(3)
    
    cluster_analysis.columns = [
        '–°—Ä_—Ñ–æ—Ç–æ', '–°—Ä_–¥–ª–∏–Ω–∞_–æ–ø–∏—Å–∞–Ω–∏—è', '–°—Ä_–ø–æ–ª–Ω–æ—Ç–∞', 
        '–°—Ä_—Å–∫–æ—Ä–æ—Å—Ç—å_–ø—É–±–ª–∏–∫–∞—Ü–∏–∏', '–°—Ä_–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å', '–î–æ–ª—è_—É—Å–ø–µ—Ö–∞', '–†–∞–∑–º–µ—Ä_–∫–ª–∞—Å—Ç–µ—Ä–∞'
    ]
    
    # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å–æ–≥–ª–∞—Å–Ω–æ –∑–∞–¥–∞–Ω–Ω—ã–º –Ω–∞–∑–≤–∞–Ω–∏—è–º
    cluster_names = {
        0: "–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∞–Ω–∫–µ—Ç—ã",
        1: "–°—Ä–µ–¥–Ω–∏–µ –∞–Ω–∫–µ—Ç—ã", 
        2: "–ü–æ–ª–Ω—ã–µ –∞–Ω–∫–µ—Ç—ã",
        3: "–ò–¥–µ–∞–ª—å–Ω—ã–µ –∞–Ω–∫–µ—Ç—ã"
    }
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Ç–µ—Ä—ã –ø–æ –∫–∞—á–µ—Å—Ç–≤—É (—Å—É–º–º–µ –∫–ª—é—á–µ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
    quality_scores = (
        cluster_analysis['–°—Ä_—Ñ–æ—Ç–æ'] + 
        cluster_analysis['–°—Ä_–¥–ª–∏–Ω–∞_–æ–ø–∏—Å–∞–Ω–∏—è'] + 
        cluster_analysis['–°—Ä_–ø–æ–ª–Ω–æ—Ç–∞']
    )
    
    # –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –≤ –ø–æ—Ä—è–¥–∫–µ –∫–∞—á–µ—Å—Ç–≤–∞
    sorted_clusters = quality_scores.sort_values().index
    for i, cluster_id in enumerate(sorted_clusters):
        if i == 0:
            cluster_names[cluster_id] = "–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∞–Ω–∫–µ—Ç—ã"
        elif i == 1:
            cluster_names[cluster_id] = "–°—Ä–µ–¥–Ω–∏–µ –∞–Ω–∫–µ—Ç—ã"
        elif i == 2:
            cluster_names[cluster_id] = "–ü–æ–ª–Ω—ã–µ –∞–Ω–∫–µ—Ç—ã"
        else:
            cluster_names[cluster_id] = "–ò–¥–µ–∞–ª—å–Ω—ã–µ –∞–Ω–∫–µ—Ç—ã"
    
    cluster_analysis['–ù–∞–∑–≤–∞–Ω–∏–µ'] = [cluster_names.get(i, '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ') for i in cluster_analysis.index]
    
    print("\n–•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò –ö–õ–ê–°–¢–ï–†–û–í:")
    print(cluster_analysis)
    
    return df_result, cluster_analysis, cluster_names

def visualize_cluster_profiles(cluster_analysis, cluster_names, clustering_dir):
    """
    –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ—Ñ–∏–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤.
    """
    print("\n–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ñ–∏–ª–µ–π –∫–ª–∞—Å—Ç–µ—Ä–æ–≤...")
    
    # 1. Radar chart –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
    fig, axes = plt.subplots(2, 2, figsize=(20, 16))
    
    # –ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è radar chart (–∏—Å–∫–ª—é—á–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏ —É—Å–ø–µ—à–Ω–æ—Å—Ç—å)
    radar_features = ['–°—Ä_—Ñ–æ—Ç–æ', '–°—Ä_–¥–ª–∏–Ω–∞_–æ–ø–∏—Å–∞–Ω–∏—è', '–°—Ä_–ø–æ–ª–Ω–æ—Ç–∞', 
                     '–°—Ä_—Å–∫–æ—Ä–æ—Å—Ç—å_–ø—É–±–ª–∏–∫–∞—Ü–∏–∏', '–°—Ä_–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å']
    n_features = len(radar_features)
    
    # –£–≥–ª—ã –¥–ª—è radar chart
    angles = np.linspace(0, 2 * np.pi, n_features, endpoint=False).tolist()
    angles += angles[:1]  # –ó–∞–º—ã–∫–∞–µ–º –∫—Ä—É–≥
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è radar chart
    normalized_data = cluster_analysis[radar_features].copy()
    for feature in radar_features:
        max_val = normalized_data[feature].max()
        if max_val > 0:
            normalized_data[feature] = normalized_data[feature] / max_val
    
    # –°–æ–∑–¥–∞–µ–º radar chart –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞
    colors = ['red', 'orange', 'lightgreen', 'darkgreen']
    
    for idx, (cluster_id, row) in enumerate(cluster_analysis.iterrows()):
        ax = axes[idx // 2, idx % 2]
        
        values = normalized_data.loc[cluster_id].values.tolist()
        values += values[:1]  # –ó–∞–º—ã–∫–∞–µ–º –∫—Ä—É–≥
        
        ax.plot(angles, values, 'o-', linewidth=2, color=colors[idx], label=cluster_names[cluster_id])
        ax.fill(angles, values, alpha=0.25, color=colors[idx])
        
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(['–§–æ—Ç–æ', '–û–ø–∏—Å–∞–Ω–∏–µ', '–ü–æ–ª–Ω–æ—Ç–∞', '–°–∫–æ—Ä–æ—Å—Ç—å', '–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å'])
        ax.set_ylim(0, 1)
        ax.set_title(f'{cluster_names[cluster_id]}\n(–£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {row["–î–æ–ª—è_—É—Å–ø–µ—Ö–∞"]:.1%})', 
                    fontsize=14, fontweight='bold')
        ax.grid(True)
    
    plt.tight_layout()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º radar chart
    radar_path = os.path.join('results/–†–µ–∑—É–ª—å—Ç–∞—Ç—ã 4 –≥–ª–∞–≤—ã –∞–Ω–∞–ª–∏–∑–∞/4.2.3. –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∞–Ω–∫–µ—Ç –≤–Ω—É—Ç—Ä–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤.png')
    plt.savefig(radar_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    # 2. Bar plot —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
    plt.figure(figsize=(12, 6))
    success_data = cluster_analysis[['–î–æ–ª—è_—É—Å–ø–µ—Ö–∞', '–ù–∞–∑–≤–∞–Ω–∏–µ']].sort_values('–î–æ–ª—è_—É—Å–ø–µ—Ö–∞')
    
    bars = plt.bar(range(len(success_data)), success_data['–î–æ–ª—è_—É—Å–ø–µ—Ö–∞'], 
                  color=['red', 'orange', 'lightgreen', 'darkgreen'])
    plt.xlabel('–¢–∏–ø –∞–Ω–∫–µ—Ç—ã')
    plt.ylabel('–î–æ–ª—è —É—Å–ø–µ—à–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤')
    plt.title('–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∞–Ω–∫–µ—Ç')
    plt.xticks(range(len(success_data)), success_data['–ù–∞–∑–≤–∞–Ω–∏–µ'], rotation=45)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
    for bar, value in zip(bars, success_data['–î–æ–ª—è_—É—Å–ø–µ—Ö–∞']):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                f'{value:.1%}', ha='center', va='bottom', fontweight='bold')
    
    plt.grid(True, alpha=0.3, axis='y')
    plt.tight_layout()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º bar plot
    bar_path = os.path.join('results/–†–µ–∑—É–ª—å—Ç–∞—Ç—ã 4 –≥–ª–∞–≤—ã –∞–Ω–∞–ª–∏–∑–∞/4.2.4. –£—Å–ø–µ—à–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞ –ø–æ —Ç–∏–ø–∞–º –∫–ª–∞—Å—Ç–µ—Ä–æ–≤.png')
    plt.savefig(bar_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    # 3. Heatmap —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
    plt.figure(figsize=(12, 8))
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è heatmap
    heatmap_data = cluster_analysis[radar_features].copy()
    heatmap_data['–†–∞–∑–º–µ—Ä'] = cluster_analysis['–†–∞–∑–º–µ—Ä_–∫–ª–∞—Å—Ç–µ—Ä–∞']
    heatmap_data['–£—Å–ø–µ—à–Ω–æ—Å—Ç—å'] = cluster_analysis['–î–æ–ª—è_—É—Å–ø–µ—Ö–∞']
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–ª—è heatmap (–∫—Ä–æ–º–µ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏)
    for feature in radar_features + ['–†–∞–∑–º–µ—Ä']:
        max_val = heatmap_data[feature].max()
        if max_val > 0:
            heatmap_data[feature] = heatmap_data[feature] / max_val
    
    sns.heatmap(heatmap_data.T, annot=True, cmap='YlOrRd', 
                fmt='.2f', linewidths=1, cbar_kws={'label': '–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ'})
    plt.title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (Heatmap)')
    plt.tight_layout()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º heatmap
    heatmap_path = os.path.join('results/–†–µ–∑—É–ª—å—Ç–∞—Ç—ã 4 –≥–ª–∞–≤—ã –∞–Ω–∞–ª–∏–∑–∞/4.2.5. –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤.png')
    plt.savefig(heatmap_path, dpi=300, bbox_inches='tight')
    plt.close()

def print_cluster_insights(cluster_analysis, cluster_names):
    """
    –í—ã–≤–æ–¥–∏—Ç –∫–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º.
    """
    print("\n" + "="*80)
    print("–ö–õ–Æ–ß–ï–í–´–ï –ò–ù–°–ê–ô–¢–´ –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–ò")
    print("="*80)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
    sorted_clusters = cluster_analysis.sort_values('–î–æ–ª—è_—É—Å–ø–µ—Ö–∞', ascending=False)
    
    for cluster_id, row in sorted_clusters.iterrows():
        name = cluster_names[cluster_id]
        success_rate = row['–î–æ–ª—è_—É—Å–ø–µ—Ö–∞']
        size = row['–†–∞–∑–º–µ—Ä_–∫–ª–∞—Å—Ç–µ—Ä–∞']
        
        print(f"\nüéØ {name.upper()}")
        print(f"   –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {success_rate:.1%} | –†–∞–∑–º–µ—Ä: {size} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
        print(f"   –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:")
        print(f"   ‚Ä¢ –§–æ—Ç–æ: {row['–°—Ä_—Ñ–æ—Ç–æ']:.1f} —à—Ç.")
        print(f"   ‚Ä¢ –î–ª–∏–Ω–∞ –æ–ø–∏—Å–∞–Ω–∏—è: {row['–°—Ä_–¥–ª–∏–Ω–∞_–æ–ø–∏—Å–∞–Ω–∏—è']:.0f} —Å–ª–æ–≤")
        print(f"   ‚Ä¢ –ü–æ–ª–Ω–æ—Ç–∞: {row['–°—Ä_–ø–æ–ª–Ω–æ—Ç–∞']:.0%}")
        print(f"   ‚Ä¢ –°–∫–æ—Ä–æ—Å—Ç—å –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {row['–°—Ä_—Å–∫–æ—Ä–æ—Å—Ç—å_–ø—É–±–ª–∏–∫–∞—Ü–∏–∏']:.1f} –¥–Ω–µ–π")
        print(f"   ‚Ä¢ –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {row['–°—Ä_–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å']:.1f} –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤")
    
    print(f"\nüìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    total_success = (cluster_analysis['–î–æ–ª—è_—É—Å–ø–µ—Ö–∞'] * cluster_analysis['–†–∞–∑–º–µ—Ä_–∫–ª–∞—Å—Ç–µ—Ä–∞']).sum()
    total_ads = cluster_analysis['–†–∞–∑–º–µ—Ä_–∫–ª–∞—Å—Ç–µ—Ä–∞'].sum()
    print(f"   –û–±—â–∞—è —É—Å–ø–µ—à–Ω–æ—Å—Ç—å: {total_success/total_ads:.1%}")
    print(f"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º:")
    for cluster_id, row in cluster_analysis.iterrows():
        percentage = row['–†–∞–∑–º–µ—Ä_–∫–ª–∞—Å—Ç–µ—Ä–∞'] / total_ads * 100
        print(f"   ‚Ä¢ {cluster_names[cluster_id]}: {percentage:.1f}%")

def step_4_2():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏.
    """
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    plt.rcParams['font.family'] = 'DejaVu Sans'
    plt.rcParams['font.size'] = 12
    sns.set_palette("husl")
    pd.set_option('display.max_columns', None)

    # –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç–∏ –∫ –≤–∞—à–∏–º —Ñ–∞–π–ª–∞–º
    LOST_FILE = 'data/Dataset_final_Pet911_lost.csv'
    FOUND_FILE = 'data/dataset_final_Pet911_found.csv'
    
    try:
        print("=== –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø –ü–û –ö–ê–ß–ï–°–¢–í–£ –û–§–û–†–ú–õ–ï–ù–ò–Ø –ê–ù–ö–ï–¢ ===")
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
        base_dir, clustering_dir = create_directories()
        
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        df = load_and_prepare_data(LOST_FILE, FOUND_FILE)
        clustering_features, df_with_features = create_clustering_features(df)
        
        # 2. –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        scaler = StandardScaler()
        features_scaled = scaler.fit_transform(clustering_features)
        feature_names = clustering_features.columns.tolist()
        
        # 3. –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        optimal_k = find_optimal_clusters(features_scaled, clustering_dir)
        
        # 4. –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
        cluster_labels, kmeans_model = perform_clustering(features_scaled, optimal_k)
        
        # 5. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤ 2D
        features_2d = visualize_clusters_2d(features_scaled, cluster_labels, feature_names, clustering_dir)
        
        # 6. –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª–µ–π –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        df_result, cluster_analysis, cluster_names = create_cluster_profiles(
            df_with_features, cluster_labels, feature_names
        )
        
        # 7. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ñ–∏–ª–µ–π
        visualize_cluster_profiles(cluster_analysis, cluster_names, clustering_dir)
        
        # 8. –í—ã–≤–æ–¥ –∏–Ω—Å–∞–π—Ç–æ–≤
        print_cluster_insights(cluster_analysis, cluster_names)
        
        # 9. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–∞–ø–∫–∏
        # CSV —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–ø–∫—É –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
        csv_result_path = os.path.join(clustering_dir, '–æ–±—ä—è–≤–ª–µ–Ω–∏—è_—Å_–∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏.csv')
        csv_analysis_path = os.path.join(clustering_dir, '–∞–Ω–∞–ª–∏–∑_–∫–ª–∞—Å—Ç–µ—Ä–æ–≤.csv')
        
        df_result.to_csv(csv_result_path, index=False, encoding='utf-8-sig')
        cluster_analysis.to_csv(csv_analysis_path, encoding='utf-8-sig')
        

        
        print(f"\nüí° –í—Å–µ —Ñ–∞–π–ª—ã —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫—É: 'results/–†–µ–∑—É–ª—å—Ç–∞—Ç—ã 4 –≥–ª–∞–≤—ã –∞–Ω–∞–ª–∏–∑–∞'")
        
    except Exception as e:
        print(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
